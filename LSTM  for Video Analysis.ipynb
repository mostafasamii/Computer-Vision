{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_Competition_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrRau8o_aFaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential , Input, Model\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D,Input,LSTM\n",
        "from keras.models import Model\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "\n",
        "\n",
        "from keras import optimizers\n",
        "from tensorflow.python import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from keras.applications import ResNet50, VGG16\n",
        "\n",
        "from keras.layers import Conv3D, MaxPooling3D, GlobalAveragePooling3D, Conv2D, BatchNormalization, MaxPooling2D, Activation, Convolution3D, ZeroPadding3D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "Train_Videos_dir = '/content/drive/My Drive/Training_set/Training'\n",
        "Test_Videos_dir = '/content/drive/My Drive/Testing_set'\n",
        "\n",
        "def Make_submission(predictions):\n",
        "    results = []\n",
        "    Myvideos = []\n",
        "\n",
        "    for pred in predictions:\n",
        "    #np.argmax return the index of the max element in the array\n",
        "        if np.argmax(pred) == 0:\n",
        "            results.append('2')\n",
        "        elif np.argmax(pred) == 1:\n",
        "            results.append('0')\n",
        "        elif np.argmax(pred) == 2:\n",
        "            results.append('1')\n",
        "        elif np.argmax(pred) == 3:\n",
        "            results.append('3')\n",
        "        elif np.argmax(pred) == 4:\n",
        "            results.append('4')\n",
        "\n",
        "    Videos = np.load('testvideos.npy')\n",
        "    for vid in Videos:\n",
        "        Myvideos.append(vid)\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        \"Videos\": Myvideos,\n",
        "        \"Label\": results\n",
        "    })\n",
        "    submission.to_csv('Submit.csv', index=False)\n",
        "    print('Done Saving Data You Can now Submit')\n",
        "\n",
        "#encoding based on the training data\n",
        "def Encoding_data(Folder_name):\n",
        "    if Folder_name == 'Basketball':\n",
        "        return np.array([1, 0, 0, 0, 0])\n",
        "    if Folder_name == 'Diving':\n",
        "        return np.array([0, 1, 0, 0, 0])\n",
        "    if Folder_name == 'Jumping':\n",
        "        return np.array([0, 0, 1, 0, 0])\n",
        "    if Folder_name == 'Tennis':\n",
        "        return np.array([0, 0, 0, 1, 0])\n",
        "    if Folder_name == 'Walking':\n",
        "        return np.array([0, 0, 0, 0, 1])\n",
        "\n",
        "#takes directory of the data and return array of [frames, label]\n",
        "def read_train_videos(Directory):\n",
        "    All_videos = []\n",
        "    All_Labels = []\n",
        "    for fold in os.listdir(Directory):\n",
        "        #Categorical enconding\n",
        "        Label = Encoding_data(fold)\n",
        "        Folder_path = os.path.join(Directory, fold)\n",
        "        for vid in tqdm(os.listdir(Folder_path)):\n",
        "            Myvideos = []\n",
        "            Video_path = os.path.join(Folder_path, vid)\n",
        "            cap = cv2.VideoCapture(Video_path)\n",
        "            nframe = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "            rem = nframe\n",
        "            cnt = 0\n",
        "            #iterates on 1 video\n",
        "            while rem >= 16:\n",
        "                ret, frame = cap.read()\n",
        "                if frame is None:\n",
        "                    break\n",
        "                if cnt < 16:\n",
        "                    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                    final_frame = cv2.resize(frame, (112, 112))\n",
        "                   \n",
        "                    #final_frame=np.reshape(final_frame,(112,112,1))\n",
        "\n",
        "                    Myvideos.append(final_frame)\n",
        "                    cnt = cnt + 1\n",
        "                else:\n",
        "                    cnt = 0\n",
        "                    All_videos.append(Myvideos)\n",
        "                    All_Labels.append(Label)\n",
        "                    Myvideos = []\n",
        "                    rem = rem - 16\n",
        "\n",
        "    FinalVideos, FinalLabels =  shuffle(All_videos, All_Labels)\n",
        "    np.save(\"All_Videos.npy\", FinalVideos)\n",
        "    np.save('Labels.npy', FinalLabels)\n",
        "    return FinalVideos, FinalLabels\n",
        "\n",
        "def read_test_videos(Directory):\n",
        "    All_videos = []\n",
        "    array_indicies=[]\n",
        "    total_sub_videos=0\n",
        "\n",
        "    for vid in tqdm(os.listdir(Directory)):\n",
        "        MyvideosList = []\n",
        "        Video_path = os.path.join(Directory, vid)\n",
        "        cap = cv2.VideoCapture(Video_path)\n",
        "        nframe = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "        rem = nframe\n",
        "        cnt = 0\n",
        "        while rem>=16:\n",
        "            ret, frame = cap.read()\n",
        "            if frame is None:\n",
        "                break\n",
        "            if cnt<16:\n",
        "                #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                final_frame = cv2.resize(frame, (112, 112))\n",
        "                #final_frame=np.reshape(final_frame,(32,32,1))\n",
        "                MyvideosList.append(final_frame)\n",
        "                cnt=cnt+1\n",
        "            else:\n",
        "                cnt = 0\n",
        "                All_videos.append(MyvideosList)\n",
        "                MyvideosList = []\n",
        "                total_sub_videos=total_sub_videos+1\n",
        "                rem = rem - 16\n",
        "        array_indicies.append(total_sub_videos) \n",
        "        total_sub_videos=0     \n",
        "        \n",
        "        \n",
        "\n",
        "    np.save('array_indicies.npy',array_indicies) \n",
        "    np.save('Testvideos.npy',All_videos)\n",
        "    return All_videos,array_indicies\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    \"\"\" Return the Keras model of the network\n",
        "    \"\"\"\n",
        "    BaseModel = VGG16(weights='imagenet', include_top=False)\n",
        "    for layer in BaseModel.layers[:-1]:\n",
        "      layer.trainable=False\n",
        "    #################################\n",
        "    model = Sequential()\n",
        "    x = Input(shape=(16, 112, 112, 3))\n",
        "    model=TimeDistributed((BaseModel))(x) \n",
        "    model=TimeDistributed((Conv2D(filters=64,kernel_size=(3,3),input_shape=(16, 112, 112, 3),padding='same')))(model)\n",
        "    model=TimeDistributed((Conv2D(filters=64,kernel_size=(3,3),input_shape=(16, 112, 112, 3),padding='same')))(model)\n",
        "    # model=LSTM(100)(model)\n",
        "    model=TimeDistributed(Dropout(0.5))(model)\n",
        "    model=Flatten()(model)\n",
        "    # model=Dense(128, activation='relu')(model)\n",
        "    model=Dense(32, activation='relu')(model)\n",
        "    # model=Dense(128, activation='relu')(model)\n",
        "    out=Dense(5, activation='softmax')(model)\n",
        "    ################################\n",
        "    model=Model(inputs = x, outputs = out)\n",
        "\n",
        "    \n",
        "    return model\n",
        "\n",
        "def run_model(Model, TrainData, TrainY, TestData):\n",
        "    opt = optimizers.adam(lr=0.00001)\n",
        "    #optimizer='adam'\n",
        "    Model.compile(loss=\"categorical_crossentropy\", optimizer= opt , metrics=[\"accuracy\"])\n",
        "    print(\"aa\")\n",
        "    print(np.shape(TrainData))\n",
        "    print(np.shape(TrainY))\n",
        "    #TrainData=TrainData.reshape(TrainData.shape[0],224,224,25,1)\n",
        "    print(np.shape(TrainData))\n",
        "\n",
        "    #train_X,valid_X,train_label,valid_label=train_test_split(TrainData, TrainY, test_size=0.2, random_state=13)\n",
        "    Model.fit(np.array(TrainData), np.array(TrainY), epochs=7, verbose=1, batch_size=8)\n",
        "    #Model.fit(np.array(train_X),np.array(train_label), validation_data=(valid_X,valid_label),epochs=30, verbose=1, batch_size=32)\n",
        "    print(\"Done training\")\n",
        "    predictions = Model.predict(np.array(TestData))\n",
        "    print(\"Done testing\")\n",
        "\n",
        "    return predictions\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if os.path.exists('/content/drive/My Drive/All_Videoss.npy'):\n",
        "        TrainData = np.load('/content/All_Videos.npy')\n",
        "        Mylabels =  np.load('/content/Labels.npy')\n",
        "        TestData = np.load('/content/Testvideos.npy',allow_pickle=True)\n",
        "        indicies=np.load('/content/array_indicies.npy')\n",
        "    else:\n",
        "        TrainData, Mylabels = read_train_videos(Train_Videos_dir)\n",
        "        TestData,indicies = read_test_videos(Test_Videos_dir)\n",
        "\n",
        "    \n",
        "    M = get_model()\n",
        "    \n",
        "\n",
        " \n",
        " \n",
        "    #softmax_L=Dense(5, activation='softmax', name='fc8')\n",
        "    #Final_model=Model(N_model.input,softmax_L)\n",
        "    #N_model=Dense(5, activation='softmax', name='fc8')(N_model)\n",
        "    print(np.shape(TestData))\n",
        "    if os.path.exists('predic.npy'):\n",
        "        Predictions=np.load('predic.npy')\n",
        "    else:\n",
        "        Predictions = run_model(M, TrainData, Mylabels, TestData)\n",
        "        np.save('predic.npy', Predictions)\n",
        "    \n",
        "    ind=0\n",
        "  \n",
        "    \n",
        "    results=[]\n",
        "    \n",
        "    for i in range(0,len(indicies)):\n",
        "        freq_arr=[0,0,0,0,0]\n",
        "        for j in range(0,indicies[i]):\n",
        "            pred=Predictions[ind+j]\n",
        "            freq_arr[0]=freq_arr[0]+pred[1]\n",
        "            freq_arr[1]=freq_arr[1]+pred[2]\n",
        "            freq_arr[2]=freq_arr[2]+pred[0]\n",
        "            freq_arr[3]=freq_arr[3]+pred[3]\n",
        "            freq_arr[4]=freq_arr[4]+pred[4]\n",
        "            #if np.argmax(pred) == 0:\n",
        "             #   freq_arr[2]=freq_arr[2]+1\n",
        "            #elif np.argmax(pred) == 1:\n",
        "             #   freq_arr[0]=freq_arr[0]+1\n",
        "            #elif np.argmax(pred) == 2:\n",
        "             #   freq_arr[1]=freq_arr[1]+1\n",
        "            #elif np.argmax(pred) == 3:\n",
        "             #   freq_arr[3]=freq_arr[3]+1\n",
        "            #elif np.argmax(pred) == 4:\n",
        "             #   freq_arr[4]=freq_arr[4]+1\n",
        "\n",
        "        results.append(np.argmax(freq_arr))\n",
        "        \n",
        "\n",
        "        ind=ind+indicies[i]\n",
        "\n",
        "\n",
        "    #np.save('predic.npy', Predictions)\n",
        "    #Make_submission(Predictions)\n",
        "    videos_names=[]\n",
        "    for vid in os.listdir(Test_Videos_dir):\n",
        "        videos_names.append(vid)\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        \"Video\": videos_names,\n",
        "        \"Label\": results\n",
        "    })\n",
        "    submission.to_csv('Submit.csv', index=False)\n",
        "    print('Done Saving Data You Can now Submit')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}